{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RbelOPK4TFB"
   },
   "source": [
    "# Data understanding\n",
    "\n",
    "The data understanding phase starts with an initial data collection and proceeds with activities in order to get familiar with the data, to identify data quality problems, to discover first insights into the data or to detect interesting subsets to form hypotheses for hidden information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wfrdzmhe0Zfr"
   },
   "source": [
    "<!-- ### task\n",
    "\n",
    "Acquire within the project the data (or access to the data) listed in the\n",
    "project resources. This initial collection includes data loading if necessary\n",
    "for data understanding. For example, if you apply a specific tool for data\n",
    "understanding, it makes perfect sense to load your data into this tool.\n",
    "This effort possibly leads to initial data preparation steps.\n",
    "\n",
    "Note: if you acquire multiple data sources, integration is an additional\n",
    "issue, either here or in the later data preparation phase.\n",
    "\n",
    "### output\n",
    "\n",
    "List the dataset (or datasets) acquired, together with their locations\n",
    "within the project, the methods used to acquire them and any problems\n",
    "encountered. Record problems encountered and any solutions achieved\n",
    "to aid with future replication of this project or with the execution of\n",
    "similar future projects.\n",
    " -->\n",
    "\n",
    "The initial dataset was obtained from the Kaggle platform, and it is publicly available by [this link](https://www.kaggle.com/datasets/mohdph/saudi-arabia-real-estate-dataset). After unzipping, I stored under the name `data/database.sqlite`. Personally, SQLite is not my favorite database, and I prefer to analyze the data using Python and its libraries such as `pandas`. After data cleaning, I will store the data in `.csv` format for future ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Sc9nvcRfYwT"
   },
   "source": [
    "<!-- ### task\n",
    "\n",
    "Examine the “gross” or “surface” properties of the acquired data and\n",
    "report on the results.\n",
    "\n",
    "### output\n",
    "\n",
    "Describe the data which has been acquired, including: the format of\n",
    "the data, the quantity of data, for example number of records and fields\n",
    "in each table, the identities of the fields and any other surface features\n",
    "of the data which have been discovered. Does the data acquired satisfy\n",
    "the relevant requirements? -->\n",
    "\n",
    "The dataset is made of `.sqlite` file, and it contains 1 table named `Listings`, which has `48` columns and `663946` rows in total. Dataset contains such features as user information, price, title, creation and update time, location, and other features related to the real estate. There are texts, dates, integers, and floats in the dataset, which can be further processed and analyzed.\n",
    "\n",
    "For the current version of the project, the dataset has all relevant information, and it is ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYGa0Os-foIw"
   },
   "source": [
    "<!-- ----------\n",
    "\n",
    "### task\n",
    "\n",
    "This task tackles the data mining questions, which can be addressed\n",
    "using querying, visualization and reporting. These include: distribution\n",
    "of key attributes, for example the target attribute of a prediction task;\n",
    "relations between pairs or small numbers of attributes; results of\n",
    "simple aggregations; properties of significant sub-populations; simple\n",
    "statistical analyses. These analyses may address directly the data mining goals; they may also contribute to or refine the data description\n",
    "and quality reports and feed into the transformation and other data\n",
    "preparation needed for further analysis.\n",
    "\n",
    "### output\n",
    "\n",
    "Describe results of this task including first findings or initial hypothesis and their impact on the remainder of the project. If appropriate,\n",
    "include graphs and plots, which indicate data characteristics or lead\n",
    "to interesting data subsets for further examination. -->\n",
    "\n",
    "From the dataset I could observe that the price is skewed to the right, and there are some outliers in the dataset having too low and too much price. This means, that there is no system in this business to restrict too low and too high prices. Also, the dataset contains some missing values, and some of the columns are not relevant for the analysis.\n",
    "\n",
    "Same we can say for the area parameter. There are some outliers in the dataset, having too big areas (which are impossible to have).\n",
    "\n",
    "Given distribution of age, we can clearly see, that a lot of people do not want to share their age (too many 0 values), therefore we should take in an account that we have less features than we thought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has no duplicates, which is good for the analysis. However, there are a lot of missing values in the dataset, and some of the columns are not relevant for the analysis, which should be properly handled. As it was previously mentioned, there are a lot of outliers in the dataset, which confirms the necessity of data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs and benefits\n",
    "\n",
    "Overall the project cost is considered to be under 1000$, because there is no much resources needed for the analysis. The benefits of the project are to understand the real estate market in Saudi Arabia, and to provide better ML model for the prediction of the price of the real estate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77gTgxgz4PYQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOdbj/NpXAo0mTrRZTN4P0/",
   "collapsed_sections": [],
   "name": "data-understanding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
